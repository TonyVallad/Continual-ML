# Continual ML - Am√©liorer une solution d'IA en continu

Un projet de d√©veloppement d'une solution d'IA avec am√©lioration continue, monitoring et automatisation sur 8 jours.

## üìã Aper√ßu du Projet

Ce projet impl√©mente une architecture compl√®te pour une solution d'IA en production avec :
- Pipeline de donn√©es automatis√© avec Prefect
- API FastAPI pour les pr√©dictions
- Monitoring avec Uptime Kuma, Prometheus & Grafana
- Notifications Discord automatiques
- Interface utilisateur Streamlit
- CI/CD avec GitHub Actions

## üöÄ Installation Rapide

```bash
# 1. Cloner le projet
git clone <repository-url>
cd Continual-ML

# 2. Configuration environnement
cp env.example .env
# Modifier .env avec vos param√®tres

# 3. Option Docker (Recommand√©e)
docker-compose up --build

# 4. Option Locale
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

---

## üìÖ D√©veloppement par Jour

### ‚úÖ Jour 1 - Infrastructure de Base (TERMIN√â)

**Objectifs :** Mise en place de l'infrastructure de monitoring et pipeline basique

**R√©alisations :**
- [x] **Discord Webhook** : Notifications automatiques configur√©es
- [x] **FastAPI Application** : API avec endpoint `/health`
- [x] **Prefect Pipeline** : Flow "random-check" toutes les 30 secondes
- [x] **Docker Compose** : Conteneurisation FastAPI + Uptime Kuma
- [x] **Configuration .env** : Variables d'environnement s√©curis√©es

**Technologies utilis√©es :**
- FastAPI, Prefect 3.1+, Docker, Uptime Kuma
- Discord Webhooks, python-dotenv

**Fonctionnalit√©s :**
- Pipeline g√©n√®re nombre al√©atoire
- Si < 0.5 ‚Üí simulation retraining (avec √©checs + retries)
- Si ‚â• 0.5 ‚Üí affiche "OK"
- Notifications Discord pour chaque √©tat
- Monitoring sant√© API via Uptime Kuma

**Comment tester :**
```bash
# D√©marrer Prefect server
prefect server start

# Dans un autre terminal
export PREFECT_API_URL=http://127.0.0.1:4200/api  # ou PowerShell: $Env:PREFECT_API_URL = "..."
python flow.py

# Acc√®s interfaces
# - API: http://localhost:8000
# - Prefect UI: http://localhost:4200
# - Uptime Kuma: http://localhost:3001
```

### ‚úÖ Jour 2 - API Compl√®te (TERMIN√â)

**Objectifs :** D√©veloppement API ML avec routes pr√©diction et gestion donn√©es

**R√©alisations :**
- [x] **Routes API Compl√®tes** :
  - `POST /predict` : Pr√©diction avec r√©gression logistique ‚úÖ
  - `GET /health` : Check sant√© ‚úÖ
  - `POST /generate` : G√©n√©ration dataset lin√©aire ‚Üí DB ‚úÖ
  - `POST /retrain` : R√©entra√Ænement avec tracking MLflow ‚úÖ
- [x] **Tests Unitaires** : Coverage compl√®te des routes
- [x] **Base de Donn√©es** : SQLite avec SQLAlchemy pour stockage datasets
- [x] **MLflow Integration** : Suivi exp√©rimentations et m√©triques mod√®les

**Technologies utilis√©es :**
- FastAPI, SQLAlchemy, MLflow, scikit-learn
- Pydantic pour validation, pytest pour tests

**Fonctionnalit√©s :**
- G√©n√©ration datasets lin√©aires 2 features
- Entra√Ænement r√©gression logistique
- Pr√©dictions avec probabilit√©s
- Tracking automatique MLflow
- Stockage persistant SQLite

### ‚úÖ Jour 3 - Monitoring & Surveillance (TERMIN√â)

**Objectifs :** Monitoring avanc√©, logging et interface utilisateur

**R√©alisations :**
- [x] **Documentation** : README d√©taill√©, guides utilisation
- [x] **CI/CD** : GitHub Actions pipeline avec tests automatis√©s
- [x] **Monitoring & Logging** :
  - Loguru : Logging structur√© rempla√ßant print/logging basique ‚úÖ
  - Performance-based retraining : Mesure performance avant retrain ‚úÖ
  - Uptime Kuma : Monitoring API health (d√©j√† configur√©) ‚úÖ
- [x] **Interface Streamlit** : Dashboard web avec authentification
- [x] **API Tokens** : S√©curit√© authentification Bearer token
- [x] **Docker Integration** : Services Streamlit dans compose

**Technologies utilis√©es :**
- Loguru, Streamlit, GitHub Actions
- FastAPI Security, Bearer authentication
- Docker multi-services

**Fonctionnalit√©s :**
- Dashboard web interactif (port 8501)
- Authentification par mot de passe Streamlit
- API s√©curis√©e par tokens Bearer
- Logging structur√© avec niveaux
- Retraining intelligent bas√© performance
- Pipeline CI/CD automatis√©

### üéØ Jour 4 - Premi√®re Restitution (√Ä VENIR)

**Objectifs :** Pr√©sentation, automatisation compl√®te

**Pr√©visions :**
- [ ] **Daily & Slides** : Pr√©sentation progr√®s
- [ ] **Document Technique** : Architecture d√©taill√©e
- [ ] **Automatisation Prefect** : Suppression route manuelle retrain
- [ ] **Discord Integration** : Logs/d√©rives automatiques
- [ ] **Template Cr√©ation** : R√©utilisabilit√© projet
- [ ] **Analyse R√©flexive** : Difficult√©s et solutions

### ü§ñ Jours 5-8 - Projet IA Sp√©cialis√© (√Ä VENIR)

**Options projets :**
1. **Reconnaissance Audio/Photo** : Identification membres √©quipe
2. **Reconnaissance Vid√©o** : Fine-tuning YOLOv11 temps r√©el
3. **Pierre-Ciseaux-Feuille** : YOLOv11 pour jeu gestuel
4. **Projet Libre** : Innovation √©quipe
5. **Bonus Celery** : Ex√©cution asynchrone pr√©dictions

---

## üèóÔ∏è Architecture Actuelle

```
Continual-ML/
‚îú‚îÄ‚îÄ app.py                      # FastAPI application (Day 2-3)
‚îú‚îÄ‚îÄ flow.py                     # Prefect pipeline (Day 1)
‚îú‚îÄ‚îÄ streamlit_app.py           # Streamlit dashboard (Day 3)
‚îú‚îÄ‚îÄ test_app.py                # Tests unitaires (Day 2-3)
‚îú‚îÄ‚îÄ docker-compose.yml         # Multi-services container (Day 1-3)
‚îú‚îÄ‚îÄ Dockerfile                 # Application container
‚îú‚îÄ‚îÄ requirements.txt           # Dependencies Python (Day 1-3)
‚îú‚îÄ‚îÄ env.example               # Environment template (Day 1-3)
‚îú‚îÄ‚îÄ README.md                 # Documentation compl√®te
‚îú‚îÄ‚îÄ IMPLEMENTATION_SUMMARY.md # R√©sum√© impl√©mentation Day 3
‚îú‚îÄ‚îÄ .github/workflows/ci.yml  # CI/CD Pipeline (Day 3)
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ Enonce.md             # Sp√©cifications projet
```

## üîß Configuration

### Variables d'Environnement (.env)

```bash
# API Security (Jour 3)
API_KEY=your-secure-api-key-here
PERFORMANCE_THRESHOLD=0.8

# Streamlit Interface (Jour 3)
STREAMLIT_PASSWORD=admin123
API_BASE_URL=http://localhost:8000

# Discord Integration
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/REPLACE_WITH_YOUR_WEBHOOK_URL

# Prefect Flow Configuration
CHECK_INTERVAL_SECONDS=30
TASK_RETRIES=2
RETRY_DELAY_SECONDS=1

# FastAPI Configuration
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000
```

## üìà Monitoring

### Services Op√©rationnels
- **FastAPI API** : Port 8000 (avec authentification Bearer token)
- **Streamlit Dashboard** : Port 8501 (interface web avec auth)
- **Uptime Kuma** : Port 3001 (monitoring sant√© API)
- **Prefect Server** : Port 4200 (workflows et pipelines)

### Fonctionnalit√©s Monitoring
- **Loguru Logging** : Logs structur√©s avec niveaux (INFO, WARNING, ERROR)
- **Performance Tracking** : Suivi automatique performance mod√®les
- **Health Checks** : Monitoring continu via Uptime Kuma
- **Discord Alerts** : Notifications automatiques drift/erreurs
- **CI/CD Pipeline** : Tests automatis√©s GitHub Actions

## üîî Notifications

Le syst√®me envoie automatiquement des notifications Discord pour :
- ‚úÖ Mod√®le performance OK
- üîÑ D√©tection drift + retraining
- ‚ùå √âchecs pipeline

## üß™ Tests

```bash
# Tests unitaires complets (Day 2-3)
pip install -r requirements.txt
pytest test_app.py -v

# Tests avec authentification
export API_KEY=your-api-key  # ou $Env:API_KEY = "..." sur Windows
pytest test_app.py -v

# Tests API manuels
curl http://localhost:8000/health
curl -H "Authorization: Bearer your-api-key" http://localhost:8000/model-status
```

## üìä Progr√®s Global

### ‚úÖ Jours Compl√©t√©s : 3/8

- **Jour 1** ‚úÖ : Infrastructure base (Prefect, FastAPI, Docker, Monitoring)  
- **Jour 2** ‚úÖ : API ML compl√®te (Pr√©dictions, MLflow, Tests, Base donn√©es)
- **Jour 3** ‚úÖ : Monitoring avanc√© (Streamlit, Auth, CI/CD, Loguru)
- **Jour 4** üü° : Restitution et automatisation (√Ä venir)
- **Jours 5-8** üü° : Projet IA sp√©cialis√© (√Ä venir)

## üìö Documentation

- [Setup Jour 1](setup_day1.md) : Guide installation d√©taill√©
- [Sp√©cifications](docs/Enonce.md) : Cahier charges complet

## ü§ù Contribution

1. Fork le projet
2. Cr√©er branche feature (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push branche (`git push origin feature/amazing-feature`)
5. Ouvrir Pull Request

## üìù Licence

Ce projet est sous licence [MIT](LICENSE).

## üè∑Ô∏è Statut D√©veloppement

- üü¢ **Jour 1** : Infrastructure de base - TERMIN√â
- üü° **Jour 2** : API ML compl√®te - EN ATTENTE
- üü° **Jour 3** : Monitoring avanc√© - EN ATTENTE
- üü° **Jour 4** : Restitution - EN ATTENTE
- üü° **Jours 5-8** : Projet IA sp√©cialis√© - EN ATTENTE

## Day 3 Features

This implementation includes all Day 3 requirements:

### ‚úÖ Implemented Features

- **üîí API Authentication**: Bearer token authentication for all endpoints
- **üìä Performance-based Retraining**: Models only retrain if performance drops below threshold
- **üìù Loguru Logging**: Structured logging throughout the application
- **üåê Streamlit Interface**: Web dashboard with authentication for API interaction
- **üîÑ CI/CD Pipeline**: GitHub Actions workflow for automated testing
- **üìà Uptime Monitoring**: Integration with Uptime Kuma for API health checks

## Quick Start

### 1. Environment Setup

```bash
# Copy environment template
cp env.example .env

# Edit .env with your configuration
# Set API_KEY, STREAMLIT_PASSWORD, etc.
```

### 2. Run with Docker Compose

```bash
docker-compose up -d
```

This starts:
- **FastAPI**: http://localhost:8000 (API)
- **Streamlit**: http://localhost:8501 (Web Interface)
- **Uptime Kuma**: http://localhost:3001 (Monitoring)

### 3. Access the Web Interface

1. Go to http://localhost:8501
2. Enter the password (default: `admin123`)
3. Use the dashboard to interact with the API

## API Endpoints

All protected endpoints require `Authorization: Bearer <API_KEY>` header.

- `GET /health` - Health check (no auth required)
- `GET /model-status` - Model status and performance (no auth required)
- `POST /generate` - Generate training dataset üîí
- `POST /retrain` - Retrain model (with performance check) üîí
- `POST /predict` - Make predictions üîí

## Configuration

Key environment variables:

- `API_KEY`: Authentication key for API access
- `PERFORMANCE_THRESHOLD`: Minimum model performance (default: 0.8)
- `STREAMLIT_PASSWORD`: Web interface password
- `DISCORD_WEBHOOK_URL`: Optional Discord notifications

## Development

### Run Tests

```bash
pip install -r requirements.txt
pytest test_app.py -v
```

### Local Development

```bash
# Start API
python app.py

# Start Streamlit (in another terminal)
streamlit run streamlit_app.py

# Start Prefect flow (in another terminal)
python flow.py
```

## Monitoring & Alerting

- **Uptime Kuma**: Configure to monitor `http://fastapi_app:8000/health` every minute
- **Discord**: Set webhook URL for drift notifications
- **Loguru**: Structured logs with different levels (INFO, WARNING, ERROR)

## CI/CD

GitHub Actions automatically:
- Runs tests on push/PR
- Validates app startup
- Caches dependencies for faster builds