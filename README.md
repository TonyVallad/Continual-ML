# Continual ML - AmÃ©liorer une solution d'IA en continu

Un projet de dÃ©veloppement d'une solution d'IA avec amÃ©lioration continue, monitoring et automatisation sur 8 jours.

## ðŸ“‹ AperÃ§u du Projet

Ce projet implÃ©mente une architecture complÃ¨te pour une solution d'IA en production avec :
- Pipeline de donnÃ©es automatisÃ© avec Prefect
- API FastAPI pour les prÃ©dictions
- Monitoring avec Uptime Kuma, Prometheus & Grafana
- Notifications Discord automatiques
- Interface utilisateur Streamlit
- CI/CD avec GitHub Actions

## ðŸš€ Installation Rapide

```bash
# 1. Cloner le projet
git clone <repository-url>
cd Continual-ML

# 2. Configuration environnement
cp env.example .env
# Modifier .env avec vos paramÃ¨tres

# 3. Option Docker (RecommandÃ©e)
docker-compose up --build

# 4. Option Locale
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

---

## ðŸ“… DÃ©veloppement par Jour

### âœ… Jour 1 - Infrastructure de Base (TERMINÃ‰)

**Objectifs :** Mise en place de l'infrastructure de monitoring et pipeline basique

**RÃ©alisations :**
- [x] **Discord Webhook** : Notifications automatiques configurÃ©es
- [x] **FastAPI Application** : API avec endpoint `/health`
- [x] **Prefect Pipeline** : Flow "random-check" toutes les 30 secondes
- [x] **Docker Compose** : Conteneurisation FastAPI + Uptime Kuma
- [x] **Configuration .env** : Variables d'environnement sÃ©curisÃ©es

**Technologies utilisÃ©es :**
- FastAPI, Prefect 3.1+, Docker, Uptime Kuma
- Discord Webhooks, python-dotenv

**FonctionnalitÃ©s :**
- Pipeline gÃ©nÃ¨re nombre alÃ©atoire
- Si < 0.5 â†’ simulation retraining (avec Ã©checs + retries)
- Si â‰¥ 0.5 â†’ affiche "OK"
- Notifications Discord pour chaque Ã©tat
- Monitoring santÃ© API via Uptime Kuma

**Comment tester :**
```bash
# DÃ©marrer Prefect server
prefect server start

# Dans un autre terminal
export PREFECT_API_URL=http://127.0.0.1:4200/api  # ou PowerShell: $Env:PREFECT_API_URL = "..."
python flow.py

# AccÃ¨s interfaces
# - API: http://localhost:8000
# - Prefect UI: http://localhost:4200
# - Uptime Kuma: http://localhost:3001
```

### âœ… Jour 2 - API ComplÃ¨te (TERMINÃ‰)

**Objectifs :** DÃ©veloppement API ML avec routes prÃ©diction et gestion donnÃ©es

**RÃ©alisations :**
- [x] **Routes API ComplÃ¨tes** :
  - `POST /predict` : PrÃ©diction avec rÃ©gression logistique âœ…
  - `GET /health` : Check santÃ© âœ…
  - `POST /generate` : GÃ©nÃ©ration dataset linÃ©aire â†’ DB âœ…
  - `POST /retrain` : RÃ©entraÃ®nement avec tracking MLflow âœ…
- [x] **Tests Unitaires** : Coverage complÃ¨te des routes
- [x] **Base de DonnÃ©es** : SQLite avec SQLAlchemy pour stockage datasets
- [x] **MLflow Integration** : Suivi expÃ©rimentations et mÃ©triques modÃ¨les

**Technologies utilisÃ©es :**
- FastAPI, SQLAlchemy, MLflow, scikit-learn
- Pydantic pour validation, pytest pour tests

**FonctionnalitÃ©s :**
- GÃ©nÃ©ration datasets linÃ©aires 2 features
- EntraÃ®nement rÃ©gression logistique
- PrÃ©dictions avec probabilitÃ©s
- Tracking automatique MLflow
- Stockage persistant SQLite

### âœ… Jour 3 - Monitoring & Surveillance (TERMINÃ‰)

**Objectifs :** Monitoring avancÃ©, logging et interface utilisateur

**RÃ©alisations :**
- [x] **Documentation** : README dÃ©taillÃ©, guides utilisation
- [x] **CI/CD** : GitHub Actions pipeline avec tests automatisÃ©s
- [x] **Monitoring & Logging** :
  - Loguru : Logging structurÃ© remplaÃ§ant print/logging basique âœ…
  - Performance-based retraining : Mesure performance avant retrain âœ…
  - Uptime Kuma : Monitoring API health (dÃ©jÃ  configurÃ©) âœ…
- [x] **Interface Streamlit** : Dashboard web avec authentification
- [x] **API Tokens** : SÃ©curitÃ© authentification Bearer token
- [x] **Docker Integration** : Services Streamlit dans compose

**Technologies utilisÃ©es :**
- Loguru, Streamlit, GitHub Actions
- FastAPI Security, Bearer authentication
- Docker multi-services

**FonctionnalitÃ©s :**
- Dashboard web interactif (port 8501)
- Authentification par mot de passe Streamlit
- API sÃ©curisÃ©e par tokens Bearer
- Logging structurÃ© avec niveaux
- Retraining intelligent basÃ© performance
- Pipeline CI/CD automatisÃ©

### ðŸŽ¯ Jour 4 - PremiÃ¨re Restitution (Ã€ VENIR)

**Objectifs :** PrÃ©sentation, automatisation complÃ¨te

**PrÃ©visions :**
- [ ] **Daily & Slides** : PrÃ©sentation progrÃ¨s
- [ ] **Document Technique** : Architecture dÃ©taillÃ©e
- [ ] **Automatisation Prefect** : Suppression route manuelle retrain
- [ ] **Discord Integration** : Logs/dÃ©rives automatiques
- [ ] **Template CrÃ©ation** : RÃ©utilisabilitÃ© projet
- [ ] **Analyse RÃ©flexive** : DifficultÃ©s et solutions

### ðŸ¤– Jours 5-8 - Projet IA SpÃ©cialisÃ© (Ã€ VENIR)

**Options projets :**
1. **Reconnaissance Audio/Photo** : Identification membres Ã©quipe
2. **Reconnaissance VidÃ©o** : Fine-tuning YOLOv11 temps rÃ©el
3. **Pierre-Ciseaux-Feuille** : YOLOv11 pour jeu gestuel
4. **Projet Libre** : Innovation Ã©quipe
5. **Bonus Celery** : ExÃ©cution asynchrone prÃ©dictions

---

## ðŸ—ï¸ Architecture Actuelle

```
Continual-ML/
â”œâ”€â”€ app.py                      # FastAPI application (Day 2-3)
â”œâ”€â”€ flow.py                     # Prefect pipeline (Day 1)
â”œâ”€â”€ streamlit_app.py           # Streamlit dashboard (Day 3)
â”œâ”€â”€ test_app.py                # Tests unitaires (Day 2-3)
â”œâ”€â”€ docker-compose.yml         # Multi-services container (Day 1-3)
â”œâ”€â”€ Dockerfile                 # Application container
â”œâ”€â”€ requirements.txt           # Dependencies Python (Day 1-3)
â”œâ”€â”€ env.example               # Environment template (Day 1-3)
â”œâ”€â”€ README.md                 # Documentation complÃ¨te
â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md # RÃ©sumÃ© implÃ©mentation Day 3
â”œâ”€â”€ .github/workflows/ci.yml  # CI/CD Pipeline (Day 3)
â””â”€â”€ docs/
    â””â”€â”€ Enonce.md             # SpÃ©cifications projet
```

## ðŸ”§ Configuration

### Variables d'Environnement (.env)

```bash
# API Security (Jour 3)
API_KEY=your-secure-api-key-here
PERFORMANCE_THRESHOLD=0.8

# Streamlit Interface (Jour 3)
STREAMLIT_PASSWORD=admin123
API_BASE_URL=http://localhost:8000

# Discord Integration
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/REPLACE_WITH_YOUR_WEBHOOK_URL

# Prefect Flow Configuration
CHECK_INTERVAL_SECONDS=30
TASK_RETRIES=2
RETRY_DELAY_SECONDS=1

# FastAPI Configuration
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000
```

## ðŸ“ˆ Monitoring

### Services OpÃ©rationnels
- **FastAPI API** : Port 8000 (avec authentification Bearer token)
- **Streamlit Dashboard** : Port 8501 (interface web avec auth)
- **Uptime Kuma** : Port 3001 (monitoring santÃ© API)
- **Prefect Server** : Port 4200 (workflows et pipelines)

### FonctionnalitÃ©s Monitoring
- **Loguru Logging** : Logs structurÃ©s avec niveaux (INFO, WARNING, ERROR)
- **Performance Tracking** : Suivi automatique performance modÃ¨les
- **Health Checks** : Monitoring continu via Uptime Kuma
- **Discord Alerts** : Notifications automatiques drift/erreurs
- **CI/CD Pipeline** : Tests automatisÃ©s GitHub Actions

## ðŸ”” Notifications

Le systÃ¨me envoie automatiquement des notifications Discord pour :
- âœ… ModÃ¨le performance OK
- ðŸ”„ DÃ©tection drift + retraining
- âŒ Ã‰checs pipeline

## ðŸ§ª Tests

```bash
# Tests unitaires complets (Day 2-3)
pip install -r requirements.txt
pytest test_app.py -v

# Tests avec authentification
export API_KEY=your-api-key  # ou $Env:API_KEY = "..." sur Windows
pytest test_app.py -v

# Tests API manuels
curl http://localhost:8000/health
curl -H "Authorization: Bearer your-api-key" http://localhost:8000/model-status
```

## ðŸ“Š ProgrÃ¨s Global

### âœ… Jours ComplÃ©tÃ©s : 3/8

- **Jour 1** âœ… : Infrastructure base (Prefect, FastAPI, Docker, Monitoring)  
- **Jour 2** âœ… : API ML complÃ¨te (PrÃ©dictions, MLflow, Tests, Base donnÃ©es)
- **Jour 3** âœ… : Monitoring avancÃ© (Streamlit, Auth, CI/CD, Loguru)
- **Jour 4** ðŸŸ¡ : Restitution et automatisation (Ã€ venir)
- **Jours 5-8** ðŸŸ¡ : Projet IA spÃ©cialisÃ© (Ã€ venir)

## ðŸ“š Documentation

- [Setup Jour 1](setup_day1.md) : Guide installation dÃ©taillÃ©
- [SpÃ©cifications](docs/Enonce.md) : Cahier charges complet

## ðŸ¤ Contribution

1. Fork le projet
2. CrÃ©er branche feature (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push branche (`git push origin feature/amazing-feature`)
5. Ouvrir Pull Request

## ðŸ“ Licence

Ce projet est sous licence [MIT](LICENSE).

## ðŸ·ï¸ Statut DÃ©veloppement

- ðŸŸ¢ **Jour 1** : Infrastructure de base - TERMINÃ‰
- ðŸŸ¡ **Jour 2** : API ML complÃ¨te - EN ATTENTE
- ðŸŸ¡ **Jour 3** : Monitoring avancÃ© - EN ATTENTE
- ðŸŸ¡ **Jour 4** : Restitution - EN ATTENTE
- ðŸŸ¡ **Jours 5-8** : Projet IA spÃ©cialisÃ© - EN ATTENTE

## Day 3 Features

This implementation includes all Day 3 requirements:

### âœ… Implemented Features

- **ðŸ”’ API Authentication**: Bearer token authentication for all endpoints
- **ðŸ“Š Performance-based Retraining**: Models only retrain if performance drops below threshold
- **ðŸ“ Loguru Logging**: Structured logging throughout the application
- **ðŸŒ Streamlit Interface**: Web dashboard with authentication for API interaction
- **ðŸ”„ CI/CD Pipeline**: GitHub Actions workflow for automated testing
- **ðŸ“ˆ Uptime Monitoring**: Integration with Uptime Kuma for API health checks

## Quick Start

### 1. Environment Setup

```bash
# Copy environment template
cp env.example .env

# Edit .env with your configuration
# Set API_KEY, STREAMLIT_PASSWORD, etc.
```

### 2. Run with Docker Compose

```bash
docker-compose up -d
```

This starts:
- **FastAPI**: http://localhost:8000 (API)
- **Streamlit**: http://localhost:8501 (Web Interface)
- **Uptime Kuma**: http://localhost:3001 (Monitoring)

### 3. Access the Web Interface

1. Go to http://localhost:8501
2. Enter the password (default: `admin123`)
3. Use the dashboard to interact with the API

## API Endpoints

All protected endpoints require `Authorization: Bearer <API_KEY>` header.

- `GET /health` - Health check (no auth required)
- `GET /model-status` - Model status and performance (no auth required)
- `POST /generate` - Generate training dataset ðŸ”’
- `POST /retrain` - Retrain model (with performance check) ðŸ”’
- `POST /predict` - Make predictions ðŸ”’

## Configuration

Key environment variables:

- `API_KEY`: Authentication key for API access
- `PERFORMANCE_THRESHOLD`: Minimum model performance (default: 0.8)
- `STREAMLIT_PASSWORD`: Web interface password
- `DISCORD_WEBHOOK_URL`: Optional Discord notifications

## Development

### Run Tests

```bash
pip install -r requirements.txt
pytest test_app.py -v
```

### Local Development

```bash
# Start API
python app.py

# Start Streamlit (in another terminal)
streamlit run streamlit_app.py

# Start Prefect flow (in another terminal)
python flow.py
```

## Monitoring & Alerting

- **Uptime Kuma**: Configure to monitor `http://fastapi_app:8000/health` every minute
- **Discord**: Set webhook URL for drift notifications
- **Loguru**: Structured logs with different levels (INFO, WARNING, ERROR)

## CI/CD

GitHub Actions automatically:
- Runs tests on push/PR
- Validates app startup
- Caches dependencies for faster builds